{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code provided below is designed to demonstrate the data generated by the program pipeline\n",
    "\n",
    "To begin with, the method _extract_required_metrics(report_path)_ is created that pulls all the necessary metrics from the initial reports \n",
    "and creates a data frame and a convenient table based on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract required metrics from a report file\n",
    "def extract_required_metrics(report_path):\n",
    "    try:\n",
    "        # Reading the report file\n",
    "        df = pd.read_csv(report_path, sep='\\t', header=None, names=['Metric', 'Value'])\n",
    "        \n",
    "        # Dictionary to store extracted metrics\n",
    "        metrics = {}\n",
    "        \n",
    "        # List of key metrics to extract\n",
    "        required_metrics = [\n",
    "            ('Total length', 'Total length'),\n",
    "            ('GC', 'GC (%)'),\n",
    "            ('Largest contig', 'Largest Contig'),\n",
    "            ('N50', 'N50'),\n",
    "            ('N90', 'N90'),\n",
    "            ('L50', 'L50'),\n",
    "            ('L90', 'L90'),\n",
    "            ('# N\\'s per 100 kbp', '# N\\'s per 100 kbp')\n",
    "        ]\n",
    "        \n",
    "        # Extracting and saving the values of required metrics\n",
    "        for metric_pattern, metric_name in required_metrics:\n",
    "            metric_value = df[df['Metric'].str.contains(metric_pattern, case=False, regex=False)]['Value'].values\n",
    "            if metric_value.size > 0:\n",
    "                metrics[metric_name] = metric_value[0]\n",
    "            else:\n",
    "                metrics[metric_name] = 'N/A'  # Marking as 'N/A' if the metric is missing\n",
    "        \n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {report_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to the directory containing report files\n",
    "reports_dir = './reports'\n",
    "\n",
    "# List of report files\n",
    "report_files = [file for file in os.listdir(reports_dir) if file.endswith('.tsv')]\n",
    "\n",
    "# Extracting and saving data from all report files\n",
    "all_metrics_data = {}\n",
    "for report_file in report_files:\n",
    "    # Forming the full path to the report file\n",
    "    report_path = os.path.join(reports_dir, report_file)\n",
    "    # Determining the trimming parameter name from the report file name\n",
    "    trimming_param = report_file.replace('report_scaffolds_', '').replace('.tsv', '')\n",
    "    # Extracting metrics\n",
    "    metrics = extract_required_metrics(report_path)\n",
    "    if metrics:\n",
    "        all_metrics_data[trimming_param] = metrics\n",
    "\n",
    "# Converting the data into a DataFrame\n",
    "all_metrics_df = pd.DataFrame.from_dict(all_metrics_data, orient='index').reset_index()\n",
    "all_metrics_df.rename(columns={'index': 'Trimming Parameters'}, inplace=True)\n",
    "\n",
    "# List of trimming parameters in the desired order\n",
    "sorting_order = [\n",
    "    \"NoTrimming\",\n",
    "    \"QualityTrim_Q25\",\n",
    "    \"AdapterTrim_Q25\",\n",
    "    \"LengthFilter_75\",\n",
    "    \"ComplexityFilter\",\n",
    "    \"SlidingWindow_4nt_q25\",\n",
    "    \"QualitySlidingHybrid_Q25_4nt_q25\", \n",
    "    \"QualityAdapterHybrid_Q25\", \n",
    "    \"LengthComplexityHybrid_75\", \n",
    "    \"SlidingComplexityHybrid_4nt_q25\",\n",
    "    \"AdapterSlidingHybrid_Q25_4nt_q25\", \n",
    "    \"QualityLengthHybrid_Q25_75\", \n",
    "    \"QualityComplexityHybrid_Q25\", \n",
    "    \"AdapterLengthHybrid_Q25_75\", \n",
    "    \"AdapterComplexityHybrid_Q25\", \n",
    "    \"LengthSlidingHybrid_75_4nt_Q25\", \n",
    "]\n",
    "\n",
    "# Sorting the DataFrame according to the specified order\n",
    "sorted_metrics_df = all_metrics_df.set_index('Trimming Parameters').reindex(sorting_order).reset_index()\n",
    "\n",
    "sorted_metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After that, we would like to visualize the same data, but in a more expressive way.\n",
    "\n",
    "To do this, we first define the base values for the **\"NoTrimming\"** Trimming Parameters, assuming that this is the control group or standard condition to which all other values will be compared. \n",
    "\n",
    "Next, we'll deal with data normalization: we'll initialize an empty _rows_list_ to store the normalized rows. In a loop over each row of the original DataFrame, computes the normalized deviations for each metric compared to the base values of the **\"NoTrimming\"** Trimming Parameters. If the base value of a metric is 0, the normalized deviation is set to 0 to avoid division by zero. \n",
    "\n",
    "Next, a new DataFrame _norm_deviations_ is created from the _rows_list_ of dictionaries, where each dictionary is a row with normalized values.\n",
    "\n",
    "### Data visualisation:\n",
    "\n",
    "Using _seaborn.heatmap()_, we create a heatmap to visualize the normalized deviations of genome assembly metrics relative to the **\"NoTrimming\"** method.\n",
    "\n",
    "In the heatmap, the rows correspond to the different trimming methods (Trimming Parameters) and the columns correspond to the genome assembly metrics.\n",
    "\n",
    "The colors of the heatmap cells reflect the magnitude of the normalized deviations, centered at 0, where shades of red indicate positive deviation and shades of blue indicate negative deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data\n",
    "# Make sure the data is numerical.\n",
    "for column in sorted_metrics_df.columns[1:]:  # Skip the first column with the names of trimming methods\n",
    "    sorted_metrics_df[column] = pd.to_numeric(sorted_metrics_df[column], errors='coerce')\n",
    "\n",
    "# Find the base values for \"NoTrimming\"\n",
    "base_values = sorted_metrics_df[sorted_metrics_df['Trimming Parameters'] == 'NoTrimming'].iloc[0, 1:]\n",
    "\n",
    "# Initialization of the list for storing strings\n",
    "rows_list = []\n",
    "\n",
    "# Cycle to fill the list of rows\n",
    "for index, row in sorted_metrics_df.iterrows():\n",
    "    norm_row = {'Trimming Parameters': row['Trimming Parameters']}\n",
    "    for metric in sorted_metrics_df.columns[1:]:\n",
    "        if base_values[metric] != 0:\n",
    "            norm_row[metric] = (row[metric] - base_values[metric]) / base_values[metric]\n",
    "        else:\n",
    "            norm_row[metric] = 0\n",
    "    rows_list.append(norm_row)\n",
    "\n",
    "# Creating a DataFrame from a list of strings\n",
    "norm_deviations = pd.DataFrame(rows_list, columns=sorted_metrics_df.columns)\n",
    "\n",
    "# Visualization of normalized deviations using a heat map\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(norm_deviations.iloc[:, 1:], annot=True, cmap='coolwarm', center=0, yticklabels=norm_deviations['Trimming Parameters'])\n",
    "plt.title('Normalized Deviation of Genome Assembly Metrics from No Trimming')\n",
    "plt.xlabel('Assembly Metrics')\n",
    "plt.ylabel('Trimming Methods')\n",
    "plt.xticks(rotation=45)  # Rotate signatures for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Normalized Deviation of Genome Assembly Metrics from No Trimming:\n",
    "\n",
    "First of all, we observe that Total length and GC (%) values remain almost unchanged after applying different trimming methods. This may indicate that different data trimming methods produce consistent results for these key parameters. This is a good sign indicating the reproducibility and reliability of the genome assembly process. This may also indicate that trimming methods do not significantly affect the overall genome profile, at least in terms of total length and GC content. That is, trimming methods can effectively remove low-quality or undesirable portions of the data without losing significant genomic regions. The consistency of these metrics may also reflect the high quality of the original sequencing data. If the sequencing data were of high quality with minimal low-quality regions, trimming may have minimal impact on the overall length and GC content of the assembly.\n",
    "\n",
    "The second thing that catches the eye is the red color in the heat map in all data where the **Sliding Window** trimming method was used: **SlidingWindow_4nt_q25**, **QualitySlidingHybrid_Q25_4nt_q25**, **SlidingComplexityHybrid_4nt_q25**, **AdapterSlidingHybrid_Q25_4nt_q25**, **LengthSlidingHybrid_75_4nt_Q25**.\n",
    "\n",
    "Any combination with this trimming method leads to a rather large decrease in the N50 and N90 metrics relative to the value when trimming is not used. This indicates that this trimming method, in any chosen combination, leads to a decrease in genome assembly continuity and accuracy. Most likely, this trimming method may be too aggressive and remove significant portions of the sequenced data. It is possible that this trimming method results in the removal or alteration of DNA regions that are important for proper genome assembly, which affects the final length of the contigs.\n",
    "\n",
    "In addition, all of the above combinations increase the L50 and L90 values. This means that more contigs are now required to reach 50% or 90% of the total genome assembly length, which may be the result of increased assembly fragmentation. This may indicate a decrease in assembly continuity and is likely due to the removal of significant data and the probable removal of overlaps required to assemble contigs into larger assemblies. \n",
    "\n",
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. If we notice an increase in L50 and L90 along with a decrease in N50 and N90 metrics, it is a clear sign that the trimming method leads to a decrease in assembly continuity and quality.\n",
    "2. In such a case, it is worth reconsidering the trimming parameters or choosing another method that will have less impact on important parts of the data and maintain or improve the continuity of the assembly. For example, the methods named **LengthFilter_75** (filtering by length of reads), **ComplexityFilter** (the percentage of the base that is different from its next base) and their hybrid **LengthComplexityHybrid_75** performed best in terms of reducing the number of N's per 100 kbp relative to the situation when no filters are used (25% improvement). This translates into improved assembly quality, higher continuity, and potentially improved uncertainty.  \n",
    "3. It is also important to consider the compromise between reducing errors and improving assembly continuity. In some cases, improving one aspect may lead to degradation of the other. For example, all 14 of the 15 combinations (except **LengthSlidingHybrid_75_4nt_Q25**) resulted in a decrease in the frequency of indeterminate nucleotides in the genome assembly for every 100,000 base pairs, but it also resulted in a decrease in the N50 parameter and an even greater decrease in the N90 parameter (an increase in the L50 and L90 parameters, respectively). Only the trimming method called **LengthFilter_75** again performed better than the others and showed the lowest reduction in the N50 parameter.\n",
    "4. It would be a rational next step to construct an additional Plot to demonstrate the hierarchy of trimming methods with respect to their ratio of the frequency of occurrence of uncertain nucleotides to the parameter N50. To do this, we will create 16 bar plots that display the ratio of # N's per 100 kbp to N50 for each data trimming method and sort them into a descending hierarchy of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relationship and add it as a new column to the DataFrame multiplying the result by 10,000\n",
    "sorted_metrics_df['N_Ratio_x10k'] = (sorted_metrics_df['# N\\'s per 100 kbp'] / sorted_metrics_df['N50']) * 10000\n",
    "\n",
    "# Sort the DataFrame by the new column 'N_Ratio'\n",
    "sorted_df = sorted_metrics_df.sort_values(by='N_Ratio_x10k', ascending=False)\n",
    "\n",
    "# Visualisation on one common graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = sns.barplot(x='Trimming Parameters', y='N_Ratio_x10k', data=sorted_df)\n",
    "\n",
    "plt.title('N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000)')\n",
    "plt.xlabel('Trimming Methods')\n",
    "plt.ylabel('N_Ratio (x10,000)')\n",
    "\n",
    "# Change the colour of the 'NoTrimming' signature to red\n",
    "for label in barplot.get_xticklabels():\n",
    "    if label.get_text() == 'NoTrimming':\n",
    "        label.set_color('red')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')  # Tilt signatures for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing 16 bar plots \"N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000)\":\n",
    "\n",
    "Above all, if we consider the compromise between reducing the continuity of the assembly (decreasing metric N50) and reducing the number of uncertain nucleotides (denoted as 'N') in the genome assembly for every 100,000 base pairs (indicating improved assembly quality, with fewer gaps and uncertain sites in the genomic sequence), we can observe that all trimming methods have performed better than the situation where no trimming method is used, except for all combinations of the **Sliding Window** method. From this point of view, there is no justification for using these trimming methods. On the other hand, the trimming methods **LengthFilter_75**, **ComplexityFilter** and their hybrid **LengthComplexityHybrid_75** show the best result in this metric. \n",
    "\n",
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. In such a situation, it would be useful to examine in more detail the two extremes: the worst trimming method (**Sliding Window**) and the best trimming method with different parameters (**Length Filter**) in terms of this compromise. Then compare them in detail with the situation where no trimming is used (**NoTrimming**).\n",
    "2. We run the programming pipeline again with the same raw sequencing data, but with a variety of different parameters for the two trimming methods selected above. The following 16 parameters for **Sliding Window** & 6 parameters for **Length Filter** were selected for the new run:\n",
    "   - SlidingWindow_4nt_q15\n",
    "   - SlidingWindow_4nt_q20\n",
    "   - SlidingWindow_4nt_q25\n",
    "   - SlidingWindow_4nt_q30\n",
    "   - SlidingWindow_7nt_q15\n",
    "   - SlidingWindow_7nt_q20\n",
    "   - SlidingWindow_7nt_q25\n",
    "   - SlidingWindow_7nt_q30\n",
    "   - SlidingWindow_10nt_q15\n",
    "   - SlidingWindow_10nt_q20\n",
    "   - SlidingWindow_10nt_q25\n",
    "   - SlidingWindow_10nt_q30\n",
    "   - SlidingWindow_20nt_q15\n",
    "   - SlidingWindow_20nt_q20\n",
    "   - SlidingWindow_20nt_q25\n",
    "   - SlidingWindow_20nt_q30\n",
    "   - LengthFilter_50\n",
    "   - LengthFilter_75\n",
    "   - LengthFilter_100\n",
    "   - LengthFilter_150\n",
    "   - LengthFilter_200\n",
    "   - LengthFilter_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New path to the directory with reports\n",
    "second_reports_dir = './reports_2'  \n",
    "\n",
    "# List of report files in a new directory\n",
    "second_report_files = [file for file in os.listdir(second_reports_dir) if file.endswith('.tsv')]\n",
    "\n",
    "# Extracting and saving data from all report files\n",
    "second_all_metrics_data = {}\n",
    "for report_file in second_report_files:\n",
    "    # Forming the full path to the report file\n",
    "    second_report_path = os.path.join(second_reports_dir, report_file)\n",
    "    # Determining the trimming parameter name from the second report file name\n",
    "    second_trimming_param = report_file.replace('output_scaffolds_', '').replace('.tsv', '')\n",
    "    # Extracting metrics\n",
    "    second_metrics = extract_required_metrics(second_report_path)\n",
    "    if second_metrics:\n",
    "        second_all_metrics_data[second_trimming_param] = second_metrics\n",
    "\n",
    "# Converting the data into a DataFrame\n",
    "second_all_metrics_df = pd.DataFrame.from_dict(second_all_metrics_data, orient='index').reset_index()\n",
    "second_all_metrics_df.rename(columns={'index': 'Trimming Parameters'}, inplace=True)\n",
    "\n",
    "# List of trimming parameters in the desired order\n",
    "second_sorting_order = [\n",
    "    \"NoTrimming\",\n",
    "    \"SlidingWindow_4nt_q15\",\n",
    "    \"SlidingWindow_4nt_q20\",\n",
    "    \"SlidingWindow_4nt_q25\",\n",
    "    \"SlidingWindow_4nt_q30\",\n",
    "    \"SlidingWindow_7nt_q15\",\n",
    "    \"SlidingWindow_7nt_q20\", \n",
    "    \"SlidingWindow_7nt_q25\", \n",
    "    \"SlidingWindow_7nt_q30\", \n",
    "    \"SlidingWindow_10nt_q15\",\n",
    "    \"SlidingWindow_10nt_q20\", \n",
    "    \"SlidingWindow_10nt_q25\", \n",
    "    \"SlidingWindow_10nt_q30\", \n",
    "    \"SlidingWindow_20nt_q15\", \n",
    "    \"SlidingWindow_20nt_q20\", \n",
    "    \"SlidingWindow_20nt_q25\",\n",
    "    \"SlidingWindow_20nt_q30\",\n",
    "    \"LengthFilter_50\",\n",
    "    \"LengthFilter_75\",\n",
    "    \"LengthFilter_100\",\n",
    "    \"LengthFilter_150\",\n",
    "    \"LengthFilter_200\",\n",
    "    \"LengthFilter_250\",\n",
    "]\n",
    "\n",
    "# Sorting the DataFrame according to the specified order\n",
    "second_sorted_metrics_df = second_all_metrics_df.set_index('Trimming Parameters').reindex(second_sorting_order).reset_index()\n",
    "\n",
    "second_sorted_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the data, but in a more expressive way again using a heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Make sure the data is numerical.\n",
    "for column in second_sorted_metrics_df.columns[1:]:  # Skip the first column with the names of trimming methods\n",
    "    second_sorted_metrics_df[column] = pd.to_numeric(second_sorted_metrics_df[column], errors='coerce')\n",
    "\n",
    "base_values = second_sorted_metrics_df[second_sorted_metrics_df['Trimming Parameters'] == 'NoTrimming'].iloc[0, 1:]\n",
    "\n",
    "# Initialising a list for storing strings\n",
    "second_rows_list = []\n",
    "\n",
    "# Cycle to fill the list of rows\n",
    "for index, row in second_sorted_metrics_df.iterrows():\n",
    "    second_norm_row = {'Trimming Parameters': row['Trimming Parameters']}\n",
    "    for metric in second_sorted_metrics_df.columns[1:]:\n",
    "        if base_values[metric] != 0:\n",
    "            second_norm_row[metric] = (row[metric] - base_values[metric]) / base_values[metric]\n",
    "        else:\n",
    "            second_norm_row[metric] = 0\n",
    "    second_rows_list.append(second_norm_row)\n",
    "\n",
    "# Creating a data frame from a list of strings\n",
    "second_norm_deviations = pd.DataFrame(second_rows_list, columns=second_sorted_metrics_df.columns)\n",
    "\n",
    "# Visualisation of normalized deviations using a heat map\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(second_norm_deviations.iloc[:, 1:], annot=True, cmap='coolwarm', center=0, yticklabels=second_norm_deviations['Trimming Parameters'])\n",
    "plt.title('Normalised deviations of genome assembly metrics from the \"NoTrimming\" method')\n",
    "plt.xlabel('Assembly Metrics after the second pipeline launch')\n",
    "plt.ylabel('Trimming Methods after the second pipeline launch')\n",
    "plt.xticks(rotation=45)  # Rotate signatures for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Normalized Deviation of Genome Assembly Metrics from No Trimming after the second pipeline launch:\n",
    "\n",
    "We can observe the same traceable pattern as in the previous heatmap: as the # N\\'s per 100 kbp_ parameter decreases, the _N50 (N90) parameters also decrease, while the L50 (L90) parameters increase. However, there are situations in which trimming is so terrible that there is an increase in the parameter # N\\'s per 100 kbp while the other parameters remain relatively unchanged (**SlidingWindow_7nt_q15** and **SlidingWindow_7nt_q15**), not to mention such sharp reductions in the quality of genomic assembly as with the parameters **SlidingWindow_10nt_q20** and **LengthFilter_250**.\n",
    "\n",
    "Let's dive deeper into the parameter study again and construct an additional Plot to demonstrate the hierarchy of trimming methods with respect to their ratio of the frequency of occurrence of uncertain nucleotides to the parameter N50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relationship and add it as a new column to the DataFrame multiplying the result by 10,000\n",
    "second_sorted_metrics_df['N_Ratio_x10k'] = (second_sorted_metrics_df['# N\\'s per 100 kbp'] / second_sorted_metrics_df['N50']) * 10000\n",
    "\n",
    "# Sort the DataFrame by the new column 'N_Ratio'\n",
    "second_sorted_df = second_sorted_metrics_df.sort_values(by='N_Ratio_x10k', ascending=False)\n",
    "\n",
    "# Visualisation on one common graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = sns.barplot(x='Trimming Parameters', y='N_Ratio_x10k', data=second_sorted_df)\n",
    "\n",
    "plt.title('N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000) after the second pipeline launch')\n",
    "plt.xlabel('Trimming Methods')\n",
    "plt.ylabel('N_Ratio (x10,000)')\n",
    "\n",
    "# Change the colour of the 'NoTrimming' signature to red\n",
    "for label in barplot.get_xticklabels():\n",
    "    if label.get_text() == 'NoTrimming':\n",
    "        label.set_color('red')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')  # Tilt signatures for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing 23 bar plots \"N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000) after the second pipeline launch\":\n",
    "\n",
    "Now we can observe an interesting picture that broadens our understanding of data trimming: the trimming method that we previously called unjustified (**Sliding Window**) after changing certain parameters and running the program pipeline a second time in some cases still justifies itself, i.e. gives a better assembly quality than if trimming had not been applied (**SlidingWindow_7nt_q25**, **SlidingWindow_10nt_q25**, **SlidingWindow_4nt_q15**). And, most amazingly, it performs in some cases (**SlidingWindow_4nt_q20**, **SlidingWindow_20nt_q20**, **SlidingWindow_4nt_q30**) even better than the trimming method we have previously recognized as the best (**LengthFilter_75**). On the other hand, we may observe that the trimming method, which in the previous step has been recognized as the best (**Length Filter**), may, under certain of its parameters, be unreasonable to use (**LengthFilter_250**). \n",
    "\n",
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. First, we have experimentally established that not only the choice of data trimming method is important, but also the parameters of this trimming method.\n",
    "2. Second, we realized that the created program pipeline, combined with intelligent processing and visualization of its results, gave us a more and more precise understanding of which trimming method and its parameters should be used to improve the quality of genomic assembly. Thus, we have created software that allows us to get new data every time we run it until we find the best solution.\n",
    "3. The next step would be interesting to see how the quality of genomic assembly within each of these two types of trimming varies as a function of the parameters being changed. To do this, we will visualise our data using Scatter Plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to take the **Length Filter** trimming method and use the 2D scatter plot to demonstrate how the N50 and # N's per 100 kbp (on separate 2D scatter plots) of this trimming method change as a function of its parameter. To visualize it we first need to filter the data to include only those rows that correspond to the different **Length Filter** parameters. Then we can create two 2D scatter plots: one for N50 and one for # of N's per 100 kbp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtering for the \"Length Filter\" trimming method\n",
    "length_filter_data = second_sorted_metrics_df[second_sorted_metrics_df['Trimming Parameters'].str.contains('LengthFilter')]\n",
    "\n",
    "# Extracting Length Filter parameters from 'Trimming Parameters' and sorting by them for line continuity\n",
    "length_filter_params_and_data = length_filter_data['Trimming Parameters'].str.extract('LengthFilter_(\\d+)')[0].astype(int)\n",
    "length_filter_sorted = length_filter_params_and_data.sort_values().index\n",
    "length_filter_params = length_filter_params_and_data.loc[length_filter_sorted].astype(int)\n",
    "\n",
    "# Creating a figure and a set of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))  # 1 row, 2 columns\n",
    "\n",
    "# Plotting N50 with lines connecting points on the first subplot\n",
    "axs[0].plot(length_filter_params, length_filter_data.loc[length_filter_sorted, 'N50'], marker='o', linestyle='-', color='blue', label='N50')\n",
    "axs[0].set_title('Variation of N50 depending on the Length Filter parameter')\n",
    "axs[0].set_xlabel('Length Filter parameter')\n",
    "axs[0].set_ylabel('N50 value')\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "# Plotting # N's per 100 kbp with lines connecting points on the second subplot\n",
    "axs[1].plot(length_filter_params, length_filter_data.loc[length_filter_sorted, \"# N's per 100 kbp\"], marker='o', linestyle='-', color='red', label=\"# N's per 100 kbp\")\n",
    "axs[1].set_title(\"Change of # N's per 100 kbp depending on Length Filter parameter\")\n",
    "axs[1].set_xlabel('Length Filter parameter')\n",
    "axs[1].set_ylabel(\"# N's per 100 kbp\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. Now, the inverse relationship between N50 and # N's per 100 kbp is visible.\n",
    "2. Thanks to this demonstration, we can see how the value of the **Length Filter** method parameter affects the quality of genome assembly.\n",
    "3. If we run the program pipeline again, applying the **Length Filter** trimming method with parameters around 75-50 values and below, we will likely be able to find an even better way to further enhance the quality of genome assembly.\n",
    "\n",
    "Now we want to take the **Sliding Window** trimming method and use the 3D scatter plot to demonstrate how the N_Ratio_x10k of this trimming method changes as a function of its parameters. To visualize it we first need to filter the data to include only those rows that correspond to the different **Sliding Window** parameters. Then we can create the 3D scatter plot.\n",
    "\n",
    "This code below is based on the fact that the trimming parameters for **Sliding Window** include two parameters (like window size and quality threshold) and that they are formatted in a recognizable pattern (e.g., **SlidingWindow_4nt_q20**):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Filter data for \"Sliding Window\" trimming method\n",
    "sliding_window_data = second_sorted_metrics_df[second_sorted_metrics_df['Trimming Parameters'].str.startswith('SlidingWindow')]\n",
    "\n",
    "# Extract and prepare the Sliding Window parameters for plotting\n",
    "# Assuming the format is \"SlidingWindow_[window size]nt_q[quality]\"\n",
    "window_sizes = sliding_window_data['Trimming Parameters'].str.extract('(\\d+)nt')[0].astype(int)\n",
    "quality_thresholds = sliding_window_data['Trimming Parameters'].str.extract('q(\\d+)')[0].astype(int)\n",
    "\n",
    "# Create a Plotly 3D scatter plot for N50\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=window_sizes,\n",
    "    y=quality_thresholds,\n",
    "    z=sliding_window_data['N_Ratio_x10k'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='blue', opacity=0.8)\n",
    ")])\n",
    "\n",
    "fig.update_layout(title='3D Scatter Plot of N_Ratio_x10k for Sliding Window Trimming',\n",
    "                  scene=dict(xaxis_title='Window Size',\n",
    "                             yaxis_title='Quality Threshold',\n",
    "                             zaxis_title='N_Ratio_x10k'))\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. Now, by opening this interactive 3D Scatter Plot (in the browser), we can observe each point in space along with its X, Y, and Z values. The values on the X and Y axes represent the numerical parameters of the **Sliding Window** trimming method (window size and mean quality), while the value on the Z axis corresponds to N_Ratio_x10k. The lower this value is, the better the compromise between # N's per 100 kbp and N50, and consequently, the higher the quality of the genome assembly.\n",
    "2. We can identify the lowest point on this 3D Scatter Plot. This means that its X and Y values represent the optimal window size and mean quality values for this trimming method in terms of their impact on the subsequent genome assembly.\n",
    "3. It is quite likely that if we initiate a third run of the software pipeline with window size and mean quality values near this point, we can further enhance the trimming quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "video_path = './video/Sliding Window Data Visualisation.mov'\n",
    "\n",
    "width = 800  \n",
    "height = 700 \n",
    "\n",
    "video = Video(video_path, width=width, height=height)\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_correct_metrics(report_file_path):\n",
    "    try:\n",
    "        df_correct = pd.read_csv(report_file_path, sep='\\t', header=0)\n",
    "        \n",
    "        correct_metrics = {\n",
    "            'Total length': df_correct.loc[0, 'Total length'],\n",
    "            'GC (%)': df_correct.loc[0, 'GC (%)'],\n",
    "            'Largest Contig': df_correct.loc[0, 'Largest contig'],\n",
    "            'N50': df_correct.loc[0, 'N50'],\n",
    "            'N90': df_correct.loc[0, 'N90'],\n",
    "            'L50': df_correct.loc[0, 'L50'],\n",
    "            'L90': df_correct.loc[0, 'L90'],\n",
    "            \"# N's per 100 kbp\": df_correct.loc[0, \"# N's per 100 kbp\"]\n",
    "        }\n",
    "        \n",
    "        return correct_metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {report_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# New path to the directory with reports\n",
    "third_reports_dir = './reports_3'  \n",
    "\n",
    "# List of report files in a new directory\n",
    "third_report_files = [file for file in os.listdir(third_reports_dir) if file.endswith('.tsv')]\n",
    "\n",
    "# Extracting and saving data from all report files\n",
    "third_all_metrics_data = {}\n",
    "for report_file in third_report_files:\n",
    "    # Forming the full path to the report file\n",
    "    third_report_path = os.path.join(third_reports_dir, report_file)\n",
    "    # Determining the trimming parameter name from the third report file name\n",
    "    third_trimming_param = report_file.replace('output_scaffolds_', '').replace('.tsv', '')\n",
    "    # Extracting metrics\n",
    "    third_metrics = extract_correct_metrics(third_report_path)\n",
    "    if third_metrics:\n",
    "        third_all_metrics_data[third_trimming_param] = third_metrics\n",
    "\n",
    "\n",
    "# Converting the data into a DataFrame\n",
    "third_all_metrics_df = pd.DataFrame.from_dict(third_all_metrics_data, orient='index').reset_index()\n",
    "third_all_metrics_df.rename(columns={'index': 'Trimming Parameters'}, inplace=True)\n",
    "\n",
    "# List of trimming parameters in the desired order\n",
    "third_sorting_order = [\n",
    "    \"SlidingWindow_3nt_q30\",\n",
    "    \"SlidingWindow_4nt_q30\",\n",
    "    \"SlidingWindow_4nt_q29\",\n",
    "    \"SlidingWindow_5nt_q30\",\n",
    "    \"LengthFilter_30\",\n",
    "    \"LengthFilter_35\",\n",
    "    \"LengthFilter_40\",\n",
    "    \"LengthFilter_45\",\n",
    "    \"LengthFilter_50\",\n",
    "    \"LengthFilter_55\",\n",
    "]\n",
    "\n",
    "# Sorting the DataFrame according to the specified order\n",
    "third_sorted_metrics_df = third_all_metrics_df.set_index('Trimming Parameters').reindex(third_sorting_order).reset_index()\n",
    "\n",
    "third_sorted_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtering for the \"Length Filter\" trimming method\n",
    "length_filter_data = third_sorted_metrics_df[third_sorted_metrics_df['Trimming Parameters'].str.contains('LengthFilter')]\n",
    "\n",
    "# Extracting Length Filter parameters from 'Trimming Parameters' and sorting by them for line continuity\n",
    "length_filter_params_and_data = length_filter_data['Trimming Parameters'].str.extract('LengthFilter_(\\d+)')[0].astype(int)\n",
    "length_filter_sorted = length_filter_params_and_data.sort_values().index\n",
    "length_filter_params = length_filter_params_and_data.loc[length_filter_sorted].astype(int)\n",
    "\n",
    "# Creating a figure and a set of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))  # 1 row, 2 columns\n",
    "\n",
    "# Plotting N50 with lines connecting points on the first subplot\n",
    "axs[0].plot(length_filter_params, length_filter_data.loc[length_filter_sorted, 'N50'], marker='o', linestyle='-', color='blue', label='N50')\n",
    "axs[0].set_title('Variation of N50 depending on the Length Filter parameter')\n",
    "axs[0].set_xlabel('Length Filter parameter')\n",
    "axs[0].set_ylabel('N50 value')\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "# Plotting # N's per 100 kbp with lines connecting points on the second subplot\n",
    "axs[1].plot(length_filter_params, length_filter_data.loc[length_filter_sorted, \"# N's per 100 kbp\"], marker='o', linestyle='-', color='red', label=\"# N's per 100 kbp\")\n",
    "axs[1].set_title(\"Change of # N's per 100 kbp depending on Length Filter parameter\")\n",
    "axs[1].set_xlabel('Length Filter parameter')\n",
    "axs[1].set_ylabel(\"# N's per 100 kbp\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. As we can see in the graph, we found no improvement in changing the value of the trimming method near its best previous value.\n",
    "2. Our hypothesis did not come true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relationship and add it as a new column to the DataFrame multiplying the result by 10,000\n",
    "third_sorted_metrics_df['N_Ratio_x10k'] = (third_sorted_metrics_df['# N\\'s per 100 kbp'] / third_sorted_metrics_df['N50']) * 10000\n",
    "\n",
    "# Sort the DataFrame by the new column 'N_Ratio'\n",
    "third_sorted_df = third_sorted_metrics_df.sort_values(by='N_Ratio_x10k', ascending=False)\n",
    "\n",
    "# Visualisation on one common graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = sns.barplot(x='Trimming Parameters', y='N_Ratio_x10k', data=third_sorted_df)\n",
    "\n",
    "plt.title('N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000) after the third pipeline launch')\n",
    "plt.xlabel('Trimming Methods')\n",
    "plt.ylabel('N_Ratio (x10,000)')\n",
    "\n",
    "# Change the colour of the 'NoTrimming' signature to red\n",
    "for label in barplot.get_xticklabels():\n",
    "    if label.get_text() == 'SlidingWindow_4nt_q30':\n",
    "        label.set_color('red')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')  # Tilt signatures for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. Our hypothesis came true and we found an even better way to trim the data with new parameters - **SlidingWindow_3nt_q30**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
