{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code provided below is designed to demonstrate the data generated by the program pipeline\n",
    "\n",
    "To begin with, the method _extract_required_metrics(report_path)_ is created that pulls all the necessary metrics from the initial reports \n",
    "and creates a data frame and a convenient table based on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract required metrics from a report file\n",
    "def extract_required_metrics(report_path):\n",
    "    try:\n",
    "        # Reading the report file\n",
    "        df = pd.read_csv(report_path, sep='\\t', header=None, names=['Metric', 'Value'])\n",
    "        \n",
    "        # Dictionary to store extracted metrics\n",
    "        metrics = {}\n",
    "        \n",
    "        # List of key metrics to extract\n",
    "        required_metrics = [\n",
    "            ('Total length', 'Total length'),\n",
    "            ('GC', 'GC (%)'),\n",
    "            ('Largest contig', 'Largest Contig'),\n",
    "            ('N50', 'N50'),\n",
    "            ('N90', 'N90'),\n",
    "            ('L50', 'L50'),\n",
    "            ('L90', 'L90'),\n",
    "            ('# N\\'s per 100 kbp', '# N\\'s per 100 kbp')\n",
    "        ]\n",
    "        \n",
    "        # Extracting and saving the values of required metrics\n",
    "        for metric_pattern, metric_name in required_metrics:\n",
    "            metric_value = df[df['Metric'].str.contains(metric_pattern, case=False, regex=False)]['Value'].values\n",
    "            if metric_value.size > 0:\n",
    "                metrics[metric_name] = metric_value[0]\n",
    "            else:\n",
    "                metrics[metric_name] = 'N/A'  # Marking as 'N/A' if the metric is missing\n",
    "        \n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {report_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to the directory containing report files\n",
    "reports_dir = './reports'\n",
    "\n",
    "# List of report files\n",
    "report_files = [file for file in os.listdir(reports_dir) if file.endswith('.tsv')]\n",
    "\n",
    "# Extracting and saving data from all report files\n",
    "all_metrics_data = {}\n",
    "for report_file in report_files:\n",
    "    # Forming the full path to the report file\n",
    "    report_path = os.path.join(reports_dir, report_file)\n",
    "    # Determining the trimming parameter name from the report file name\n",
    "    trimming_param = report_file.replace('report_scaffolds_', '').replace('.tsv', '')\n",
    "    # Extracting metrics\n",
    "    metrics = extract_required_metrics(report_path)\n",
    "    if metrics:\n",
    "        all_metrics_data[trimming_param] = metrics\n",
    "\n",
    "# Converting the data into a DataFrame\n",
    "all_metrics_df = pd.DataFrame.from_dict(all_metrics_data, orient='index').reset_index()\n",
    "all_metrics_df.rename(columns={'index': 'Trimming Parameters'}, inplace=True)\n",
    "\n",
    "# List of trimming parameters in the desired order\n",
    "sorting_order = [\n",
    "    \"NoTrimming\",\n",
    "    \"QualityTrim_Q25\",\n",
    "    \"AdapterTrim_Q25\",\n",
    "    \"LengthFilter_75\",\n",
    "    \"ComplexityFilter\",\n",
    "    \"SlidingWindow_4nt_q25\",\n",
    "    \"QualitySlidingHybrid_Q25_4nt_q25\", \n",
    "    \"QualityAdapterHybrid_Q25\", \n",
    "    \"LengthComplexityHybrid_75\", \n",
    "    \"SlidingComplexityHybrid_4nt_q25\",\n",
    "    \"AdapterSlidingHybrid_Q25_4nt_q25\", \n",
    "    \"QualityLengthHybrid_Q25_75\", \n",
    "    \"QualityComplexityHybrid_Q25\", \n",
    "    \"AdapterLengthHybrid_Q25_75\", \n",
    "    \"AdapterComplexityHybrid_Q25\", \n",
    "    \"LengthSlidingHybrid_75_4nt_Q25\", \n",
    "]\n",
    "\n",
    "# Sorting the DataFrame according to the specified order\n",
    "sorted_metrics_df = all_metrics_df.set_index('Trimming Parameters').reindex(sorting_order).reset_index()\n",
    "\n",
    "sorted_metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After that, we would like to visualize the same data, but in a more expressive way.\n",
    "\n",
    "To do this, we first define the base values for the **\"NoTrimming\"** Trimming Parameters, assuming that this is the control group or standard condition to which all other values will be compared. \n",
    "\n",
    "Next, we'll deal with data normalization: we'll initialize an empty _rows_list_ to store the normalized rows. In a loop over each row of the original DataFrame, computes the normalized deviations for each metric compared to the base values of the **\"NoTrimming\"** Trimming Parameters. If the base value of a metric is 0, the normalized deviation is set to 0 to avoid division by zero. \n",
    "\n",
    "Next, a new DataFrame _norm_deviations_ is created from the _rows_list_ of dictionaries, where each dictionary is a row with normalized values.\n",
    "\n",
    "### Data visualisation:\n",
    "\n",
    "Using _seaborn.heatmap()_, we create a heatmap to visualize the normalized deviations of genome assembly metrics relative to the **\"NoTrimming\"** method.\n",
    "\n",
    "In the heatmap, the rows correspond to the different trimming methods (Trimming Parameters) and the columns correspond to the genome assembly metrics.\n",
    "\n",
    "The colors of the heatmap cells reflect the magnitude of the normalized deviations, centered at 0, where shades of red indicate positive deviation and shades of blue indicate negative deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data\n",
    "# Make sure the data is numerical.\n",
    "for column in sorted_metrics_df.columns[1:]:  # Skip the first column with the names of trimming methods\n",
    "    sorted_metrics_df[column] = pd.to_numeric(sorted_metrics_df[column], errors='coerce')\n",
    "\n",
    "# Find the base values for \"NoTrimming\"\n",
    "base_values = sorted_metrics_df[sorted_metrics_df['Trimming Parameters'] == 'NoTrimming'].iloc[0, 1:]\n",
    "\n",
    "# Initialization of the list for storing strings\n",
    "rows_list = []\n",
    "\n",
    "# Cycle to fill the list of rows\n",
    "for index, row in sorted_metrics_df.iterrows():\n",
    "    norm_row = {'Trimming Parameters': row['Trimming Parameters']}\n",
    "    for metric in sorted_metrics_df.columns[1:]:\n",
    "        if base_values[metric] != 0:\n",
    "            norm_row[metric] = (row[metric] - base_values[metric]) / base_values[metric]\n",
    "        else:\n",
    "            norm_row[metric] = 0\n",
    "    rows_list.append(norm_row)\n",
    "\n",
    "# Creating a DataFrame from a list of strings\n",
    "norm_deviations = pd.DataFrame(rows_list, columns=sorted_metrics_df.columns)\n",
    "\n",
    "# Visualization of normalized deviations using a heat map\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(norm_deviations.iloc[:, 1:], annot=True, cmap='coolwarm', center=0, yticklabels=norm_deviations['Trimming Parameters'])\n",
    "plt.title('Normalized Deviation of Genome Assembly Metrics from No Trimming')\n",
    "plt.xlabel('Assembly Metrics')\n",
    "plt.ylabel('Trimming Methods')\n",
    "plt.xticks(rotation=45)  # Rotate signatures for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Normalized Deviation of Genome Assembly Metrics from No Trimming:\n",
    "\n",
    "First of all, we observe that Total length and GC (%) values remain almost unchanged after applying different trimming methods. This may indicate that different data trimming methods produce consistent results for these key parameters. This is a good sign indicating the reproducibility and reliability of the genome assembly process. This may also indicate that trimming methods do not significantly affect the overall genome profile, at least in terms of total length and GC content. That is, trimming methods can effectively remove low-quality or undesirable portions of the data without losing significant genomic regions. The consistency of these metrics may also reflect the high quality of the original sequencing data. If the sequencing data were of high quality with minimal low-quality regions, trimming may have minimal impact on the overall length and GC content of the assembly.\n",
    "\n",
    "The second thing that catches the eye is the red color in the heat map in all data where the **Sliding Window** trimming method was used: **SlidingWindow_4nt_q25**, **QualitySlidingHybrid_Q25_4nt_q25**, **SlidingComplexityHybrid_4nt_q25**, **AdapterSlidingHybrid_Q25_4nt_q25**, **LengthSlidingHybrid_75_4nt_Q25**.\n",
    "\n",
    "Any combination with this trimming method leads to a rather large decrease in the N50 and N90 metrics relative to the value when trimming is not used. This indicates that this trimming method, in any chosen combination, leads to a decrease in genome assembly continuity and accuracy. Most likely, this trimming method may be too aggressive and remove significant portions of the sequenced data. It is possible that this trimming method results in the removal or alteration of DNA regions that are important for proper genome assembly, which affects the final length of the contigs.\n",
    "\n",
    "In addition, all of the above combinations increase the L50 and L90 values. This means that more contigs are now required to reach 50% or 90% of the total genome assembly length, which may be the result of increased assembly fragmentation. This may indicate a decrease in assembly continuity and is likely due to the removal of significant data and the probable removal of overlaps required to assemble contigs into larger assemblies. \n",
    "\n",
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. If we notice an increase in L50 and L90 along with a decrease in N50 and N90 metrics, it is a clear sign that the trimming method leads to a decrease in assembly continuity and quality.\n",
    "2. In such a case, it is worth reconsidering the trimming parameters or choosing another method that will have less impact on important parts of the data and maintain or improve the continuity of the assembly. For example, the methods named **LengthFilter_75** (filtering by length of reads), **ComplexityFilter** (the percentage of the base that is different from its next base) and their hybrid **LengthComplexityHybrid_75** performed best in terms of reducing the number of N's per 100 kbp relative to the situation when no filters are used (25% improvement). This translates into improved assembly quality, higher continuity, and potentially improved uncertainty.  \n",
    "3. It is also important to consider the compromise between reducing errors and improving assembly continuity. In some cases, improving one aspect may lead to degradation of the other. For example, all 14 of the 15 combinations (except **LengthSlidingHybrid_75_4nt_Q25**) resulted in a decrease in the frequency of indeterminate nucleotides in the genome assembly for every 100,000 base pairs, but it also resulted in a decrease in the N50 parameter and an even greater decrease in the N90 parameter (an increase in the L50 and L90 parameters, respectively). Only the trimming method called **LengthFilter_75** again performed better than the others and showed the lowest reduction in the N50 parameter.\n",
    "4. It would be a rational next step to construct an additional Plot to demonstrate the hierarchy of trimming methods with respect to their ratio of the frequency of occurrence of uncertain nucleotides to the parameter N50. To do this, we will create 16 bar plots that display the ratio of # N's per 100 kbp to N50 for each data trimming method and sort them into an descending hierarchy of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relationship and add it as a new column to the DataFrame multiplying the result by 10,000\n",
    "sorted_metrics_df['N_Ratio_x10k'] = (sorted_metrics_df['# N\\'s per 100 kbp'] / sorted_metrics_df['N50']) * 10000\n",
    "\n",
    "# Sort the DataFrame by the new column 'N_Ratio'\n",
    "sorted_df = sorted_metrics_df.sort_values(by='N_Ratio_x10k', ascending=False)\n",
    "\n",
    "# Visualisation on one common graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = sns.barplot(x='Trimming Parameters', y='N_Ratio_x10k', data=sorted_df)\n",
    "\n",
    "plt.title('N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000)')\n",
    "plt.xlabel('Trimming Methods')\n",
    "plt.ylabel('N_Ratio (x10,000)')\n",
    "\n",
    "# Change the colour of the 'NoTrimming' signature to red\n",
    "for label in barplot.get_xticklabels():\n",
    "    if label.get_text() == 'NoTrimming':\n",
    "        label.set_color('red')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')  # Tilt signatures for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing 16 bar plots \"N_Ratio (# N\\'s per 100 kbp / N50) for Different Trimming Methods (Values x10,000)\":\n",
    "\n",
    "Above all, if we consider the compromise between reducing the continuity of the assembly (decreasing metric N50) and reducing the number of uncertain nucleotides (denoted as 'N') in the genome assembly for every 100,000 base pairs (indicating improved assembly quality, with fewer gaps and uncertain sites in the genomic sequence), we can observe that all trimming methods have performed better than the situation where no trimming method is used, except for all combinations of the **Sliding Window** method. From this point of view, there is no justification for using these trimming methods. On the other hand, the trimming methods **LengthFilter_75**, **ComplexityFilter** and their hybrid **LengthComplexityHybrid_75** show the best result in this metric. \n",
    "\n",
    "**What conclusions can be drawn from this?**\n",
    "\n",
    "1. In such a situation, it would be useful to examine in more detail the two extremes: the worst trimming method (**Sliding Window**) and the best trimming method with different parameters (**Length Filter**) in terms of this compromise. Then compare them in detail with the situation where no trimming is used (**NoTrimming**).\n",
    "2. We run the programming pipeline again with the same raw sequencing data, but with a variety of different parameters for the two trimming methods selected above. The following 16 parameters for **Sliding Window** & 6 parameters for **Length Filter** were selected for the new run:\n",
    "   - SlidingWindow_4nt_q15\n",
    "   - SlidingWindow_4nt_q20\n",
    "   - SlidingWindow_4nt_q25\n",
    "   - SlidingWindow_4nt_q30\n",
    "   - SlidingWindow_7nt_q15\n",
    "   - SlidingWindow_7nt_q20\n",
    "   - SlidingWindow_7nt_q25\n",
    "   - SlidingWindow_7nt_q30\n",
    "   - SlidingWindow_10nt_q15\n",
    "   - SlidingWindow_10nt_q20\n",
    "   - SlidingWindow_10nt_q25\n",
    "   - SlidingWindow_10nt_q30\n",
    "   - SlidingWindow_20nt_q15\n",
    "   - SlidingWindow_20nt_q20\n",
    "   - SlidingWindow_20nt_q25\n",
    "   - SlidingWindow_20nt_q30\n",
    "   - LengthFilter_50\n",
    "   - LengthFilter_75\n",
    "   - LengthFilter_100\n",
    "   - LengthFilter_150\n",
    "   - LengthFilter_200\n",
    "   - LengthFilter_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New path to the directory with reports\n",
    "second_reports_dir = './reports_2'  \n",
    "\n",
    "# List of report files in a new directory\n",
    "second_report_files = [file for file in os.listdir(second_reports_dir) if file.endswith('.tsv')]\n",
    "\n",
    "# Extracting and saving data from all report files\n",
    "second_all_metrics_data = {}\n",
    "for report_file in second_report_files:\n",
    "    # Forming the full path to the report file\n",
    "    second_report_path = os.path.join(second_reports_dir, report_file)\n",
    "    # Determining the trimming parameter name from the second report file name\n",
    "    second_trimming_param = report_file.replace('output_scaffolds_', '').replace('.tsv', '')\n",
    "    # Extracting metrics\n",
    "    second_metrics = extract_required_metrics(second_report_path)\n",
    "    if second_metrics:\n",
    "        second_all_metrics_data[second_trimming_param] = second_metrics\n",
    "\n",
    "# Converting the data into a DataFrame\n",
    "second_all_metrics_df = pd.DataFrame.from_dict(second_all_metrics_data, orient='index').reset_index()\n",
    "second_all_metrics_df.rename(columns={'index': 'Trimming Parameters'}, inplace=True)\n",
    "\n",
    "# List of trimming parameters in the desired order\n",
    "second_sorting_order = [\n",
    "    \"NoTrimming\",\n",
    "    \"SlidingWindow_4nt_q15\",\n",
    "    \"SlidingWindow_4nt_q20\",\n",
    "    \"SlidingWindow_4nt_q25\",\n",
    "    \"SlidingWindow_4nt_q30\",\n",
    "    \"SlidingWindow_7nt_q15\",\n",
    "    \"SlidingWindow_7nt_q20\", \n",
    "    \"SlidingWindow_7nt_q25\", \n",
    "    \"SlidingWindow_7nt_q30\", \n",
    "    \"SlidingWindow_10nt_q15\",\n",
    "    \"SlidingWindow_10nt_q20\", \n",
    "    \"SlidingWindow_10nt_q25\", \n",
    "    \"SlidingWindow_10nt_q30\", \n",
    "    \"SlidingWindow_20nt_q15\", \n",
    "    \"SlidingWindow_20nt_q20\", \n",
    "    \"SlidingWindow_20nt_q25\",\n",
    "    \"SlidingWindow_20nt_q30\",\n",
    "    \"LengthFilter_50\",\n",
    "    \"LengthFilter_75\",\n",
    "    \"LengthFilter_100\",\n",
    "    \"LengthFilter_150\",\n",
    "    \"LengthFilter_200\",\n",
    "    \"LengthFilter_250\",\n",
    "]\n",
    "\n",
    "# Sorting the DataFrame according to the specified order\n",
    "second_sorted_metrics_df = second_all_metrics_df.set_index('Trimming Parameters').reindex(second_sorting_order).reset_index()\n",
    "\n",
    "second_sorted_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
